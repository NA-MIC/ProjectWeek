---
layout: pw39-project

permalink: /:path/
redirect_from:
- /PW39_2023_Montreal/Projects/HistologyAiModelsImportedIntoIdc/README.html

project_title: Histology AI model annotations imported into IDC
category: Segmentation / Classification / Landmarking
presenter_location: In-person

key_investigators:

- name: Curtis Lisle
  affiliation: KnowledgeVis
  country: USA

- name: Daniela Schacherer
  affiliation: MEVIS
  country: Germany

- name: David Clunie
  affiliation: PixelMed
  country: USA

- name: Maximillian Fischer
  affiliation: DKFZ
  country: Germany

- name: Andrey Fedorov
  affiliation: Brigham and Women's Hospital
  country: USA

- name: Chris Bridge
  affiliation: Brigham and Women's Hospital
  country: USA

---

# Project Description

<!-- Add a short paragraph describing the project. -->

This project focuses on importing whole slide image (WSI) histology images and trained deep learning models into the Imaging Data Commons for access by others. We have developed tissue-level segmentation models for detecting subtypes of rhabdomyosarcoma (RMS) in whole slides. Our project is releasing WSIs and the corresponding models trained on the slide images.

This project will test reading DICOM-WSI imagery (including compression) and focus on how to write out model segmentation results as DICOM-WSI annotations for upload to IDC.   We also have classification and regression models, so we need to decide how to write non-imagery classification results as DICOM, as well.

## Objective

<!-- Describe here WHAT you would like to achieve (what you will have as end result). -->

*   Write out model segmentation image results as DICOM-WSI Segmentation or Parametric Map objects
*   Test models on sample DICOM-WSI images
*   Determine where to how to store regression and classification model results as DICOM annotations

## Approach and Plan

<!-- Describe here HOW you would like to achieve the objectives stated above. -->

*   Verify the algorithms run on DICOM-WSI source images (including compression)
*   Understand the semantics associated with DICOM Segmentation and Parametric Map objects (there is a lot to learn here. DICOM is powerful, but comes with some complexity).
*   Start with example workflow code from Max.  He generated a DICOM parametric map to save the output of his model.
*   Write output formatter code to generate proper DICOM for single class and multi-class segmentation images
*   Test output annotations in Slim viewer

## Progress and Next Steps

<!-- Update this section as you make progress, describing of what you have ACTUALLY DONE.
     If there are specific steps that you could not complete then you can describe them here, too. -->

* Used Kitware's Large-Image package for reading DICOM images.
* Executed Rhabdomyosarcoma detection model (reading DICOM-WSI images)
* Daniela and Chris from the IDC program were a great help with how to navigate DICOM. The HighDicom library is designed nicely.
* Thanks to David Clunie for explaining DICOM segmentation objects
* After many tries, we generated a multi-class segmentation map (a BINARY segmentation type in DICOM)
* We Previewed the image and the matching segmentation in the Slim viewer running on my laptop


# Illustrations

<!-- Add pictures and links to videos that demonstrate what has been accomplished. -->

Here is the model output drawn as an RGB pseudocolor image.  Each tissue class determined by the
model is given a different color:
![colorimage](https://data.kitware.com/api/v1/file/648a8497488633cbb1275cbd/download)

Here is the stained pathology slide image and the model output written as a DICOM segmentation image and
overlayed in the Slim viewer developed by the IDC program.  The viewer is zoomed into the right part of the image:

![dicomimage](https://data.kitware.com/api/v1/file/648a87dd488633cbb1275cc3/download)

# After Project Week
We want to extend this algorithm to address segmentation images of the same extent, but different resolution than the original image.  For this week, we kept the same resolution between the source image and the segmentation image generated by the model.

# Background and References

<!-- If you developed any software, include link to the source code repository.
     If possible, also add links to sample data, and to any relevant publications. -->

- starting example code from Max and Chris Gorman:  https://github.com/maxfscher/DICOMwsiWorkflow.git
- Repository containing the model execution code and the dicom output logic, based on the HighDicom library: [Github Link](https://github.com/knowledgevis/rms-infer-code-standalone)
