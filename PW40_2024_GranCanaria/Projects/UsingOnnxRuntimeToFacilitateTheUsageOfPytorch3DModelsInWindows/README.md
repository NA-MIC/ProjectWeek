---
layout: pw40-project

permalink: /:path/

project_title: Using ONNX runtime to facilitate the usage of PyTorch3D models in Windows
category: Infrastructure
presenter_location: Online

key_investigators:

- name: Sal Choueib
  affiliation: Ebatinca
  country: Spain

- name: Csaba Pinter
  affiliation: Ebatinca
  country: Spain

- name: Juan Ruiz Alzola
  affiliation: Ebatinca
  country: Spain

---

# Project Description

<!-- Add a short paragraph describing the project. -->

The ONNX runtime is an intermediary machine learning framework that allows users to easily convert between different machine learning frameworks. The aim in this project is to leverage ONNX to utilize PyTorch3D models in Windows.

## Objective

<!-- Describe here WHAT you would like to achieve (what you will have as end result). -->

1.  Build ONNX on a windows machine
2.  Use the ONNX runtime to load and run the following PyTorch model in windows: <https://github.com/DCBIA-OrthoLab/SlicerDentalModelSeg>
3.  Use the runtime to tune the performance of the model in windows
4.  Deploy the model

## Approach and Plan

<!-- Describe here HOW you would like to achieve the objectives stated above. -->

1.  Investigate the ONNX runtime environment
2.  Attempt to export the given PyTorch model in ONNX format
3.  Attempt to import the model and run it in the ONNX runtime in windows
4.  Investigate the performance tuning capabilities of ONNX
5.  Outline a pipeline to streamline the conversion of PyTorch models to be used on windows systems

## Progress and Next Steps

<!-- Update this section as you make progress, describing of what you have ACTUALLY DONE.
     If there are specific steps that you could not complete then you can describe them here, too. -->

*No response*

# Illustrations

<!-- Add pictures and links to videos that demonstrate what has been accomplished. -->

*No response*

# Background and References

<!-- If you developed any software, include link to the source code repository.
     If possible, also add links to sample data, and to any relevant publications. -->

*No response*
